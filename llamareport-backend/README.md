# LlamaReport Backend - ç®€åŒ–ç‰ˆ

> ä¸“æ³¨äºæ–‡æ¡£å¤„ç†å’ŒRAGé—®ç­”çš„è½»é‡çº§è´¢åŠ¡æŠ¥å‘Šåˆ†æåç«¯

## ğŸ¯ é¡¹ç›®æ¦‚è¿°

LlamaReport Backend æ˜¯åŸLlamaReportProé¡¹ç›®çš„ç®€åŒ–ç‰ˆæœ¬ï¼Œç§»é™¤äº†å¤æ‚çš„å‰ç«¯ç•Œé¢å’Œå¯è§†åŒ–åŠŸèƒ½ï¼Œä¸“æ³¨äºæ ¸å¿ƒçš„æ–‡æ¡£å¤„ç†å’Œæ™ºèƒ½é—®ç­”èƒ½åŠ›ã€‚

### æ ¸å¿ƒåŠŸèƒ½

- ğŸ“„ **PDFæ–‡æ¡£å¤„ç†** - æ–‡æœ¬æå–å’Œé¢„å¤„ç†
- ğŸ“Š **è¡¨æ ¼æ•°æ®æå–** - è´¢åŠ¡è¡¨æ ¼è¯†åˆ«å’Œåˆ†æ
- ğŸ¤– **RAGæ™ºèƒ½é—®ç­”** - åŸºäºæ–‡æ¡£å†…å®¹çš„æ™ºèƒ½é—®ç­”
- ğŸ” **å‘é‡æ£€ç´¢** - é«˜æ•ˆçš„è¯­ä¹‰æœç´¢

### æŠ€æœ¯æ ˆ

- **Webæ¡†æ¶**: FastAPI
- **æ–‡æ¡£å¤„ç†**: LlamaIndex + PDFPlumber
- **å‘é‡æ•°æ®åº“**: ChromaDB
- **LLMæœåŠ¡**: OpenAI GPT-4
- **æ•°æ®å¤„ç†**: Pandas

## ğŸš€ å¿«é€Ÿå¼€å§‹

### 1. ç¯å¢ƒè¦æ±‚

- Python 3.8+
- OpenAI API Key

### 2. å®‰è£…ä¾èµ–

```bash
cd llamareport-backend
pip install -r requirements.txt
```

### 3. ç¯å¢ƒé…ç½®

åˆ›å»º `.env` æ–‡ä»¶ï¼š

```env
OPENAI_API_KEY=your-openai-api-key-here
OPENAI_MODEL=gpt-4o-mini
```

### 4. å¯åŠ¨æœåŠ¡

```bash
# æ–¹å¼1: ä½¿ç”¨å¯åŠ¨è„šæœ¬ï¼ˆæ¨èï¼‰
python start.py

# æ–¹å¼2: ç›´æ¥å¯åŠ¨
python main.py

# æ–¹å¼3: ä½¿ç”¨uvicorn
uvicorn main:app --host 0.0.0.0 --port 8000 --reload
```

### 5. è®¿é—®API

- **APIæ–‡æ¡£**: http://localhost:8000/docs
- **ä¸»é¡µ**: http://localhost:8000
- **å¥åº·æ£€æŸ¥**: http://localhost:8000/health

## ğŸ“š APIæ¥å£

### æ–‡ä»¶ä¸Šä¼ 

```bash
# ä¸Šä¼ å•ä¸ªæ–‡ä»¶
curl -X POST "http://localhost:8000/upload/file" \
  -H "Content-Type: multipart/form-data" \
  -F "file=@report.pdf"

# æŸ¥çœ‹å·²ä¸Šä¼ æ–‡ä»¶
curl "http://localhost:8000/upload/list"
```

### æ–‡æ¡£å¤„ç†

```bash
# å¤„ç†æ–‡æ¡£å¹¶æ„å»ºç´¢å¼•
curl -X POST "http://localhost:8000/process/file" \
  -H "Content-Type: application/json" \
  -d '{"filename": "report.pdf", "build_index": true}'

# æŸ¥çœ‹å¤„ç†çŠ¶æ€
curl "http://localhost:8000/process/status"
```

### æ™ºèƒ½é—®ç­”

```bash
# æé—®
curl -X POST "http://localhost:8000/query/ask" \
  -H "Content-Type: application/json" \
  -d '{"question": "å…¬å¸çš„è¥ä¸šæ”¶å…¥æ˜¯å¤šå°‘ï¼Ÿ"}'

# è·å–ç›¸ä¼¼å†…å®¹
curl -X POST "http://localhost:8000/query/similar" \
  -H "Content-Type: application/json" \
  -d '{"query": "è´¢åŠ¡æ•°æ®", "top_k": 5}'
```

## ğŸ—ï¸ é¡¹ç›®ç»“æ„

```
llamareport-backend/
â”œâ”€â”€ main.py              # FastAPIä¸»åº”ç”¨
â”œâ”€â”€ config.py            # é…ç½®ç®¡ç†
â”œâ”€â”€ requirements.txt     # ä¾èµ–åŒ…åˆ—è¡¨
â”œâ”€â”€ .env                 # ç¯å¢ƒå˜é‡
â”œâ”€â”€ start.py             # å¯åŠ¨è„šæœ¬
â”œâ”€â”€ test_backend.py      # æµ‹è¯•è„šæœ¬
â”œâ”€â”€ README.md            # é¡¹ç›®æ–‡æ¡£
â”œâ”€â”€ core/                # æ ¸å¿ƒæ¨¡å—
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ document_processor.py  # æ–‡æ¡£å¤„ç†å™¨
â”‚   â”œâ”€â”€ table_extractor.py     # è¡¨æ ¼æå–å™¨
â”‚   â””â”€â”€ rag_engine.py          # RAGå¼•æ“
â”œâ”€â”€ api/                 # APIæ¥å£
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ upload.py        # æ–‡ä»¶ä¸Šä¼ æ¥å£
â”‚   â”œâ”€â”€ process.py       # æ–‡æ¡£å¤„ç†æ¥å£
â”‚   â””â”€â”€ query.py         # æŸ¥è¯¢æ¥å£
â”œâ”€â”€ uploads/             # ä¸Šä¼ æ–‡ä»¶ç›®å½•
â””â”€â”€ storage/             # æ•°æ®å­˜å‚¨ç›®å½•
    â””â”€â”€ chroma/          # ChromaDBæ•°æ®
```

## ğŸ§ª æµ‹è¯•

```bash
# è¿è¡Œå®Œæ•´æµ‹è¯•
python test_backend.py

# æµ‹è¯•ç‰¹å®šåŠŸèƒ½
python -c "from test_backend import test_imports; test_imports()"
```

## ğŸ“– ä½¿ç”¨ç¤ºä¾‹

### å®Œæ•´å·¥ä½œæµç¨‹

```python
import requests

base_url = "http://localhost:8000"

# 1. ä¸Šä¼ æ–‡ä»¶
with open("financial_report.pdf", "rb") as f:
    response = requests.post(f"{base_url}/upload/file", files={"file": f})
    print(response.json())

# 2. å¤„ç†æ–‡æ¡£
response = requests.post(f"{base_url}/process/file", 
    json={"filename": "financial_report.pdf", "build_index": True})
print(response.json())

# 3. æ™ºèƒ½é—®ç­”
response = requests.post(f"{base_url}/query/ask",
    json={"question": "å…¬å¸å»å¹´çš„å‡€åˆ©æ¶¦æ˜¯å¤šå°‘ï¼Ÿ"})
print(response.json())
```

## âš™ï¸ é…ç½®é€‰é¡¹

### ç¯å¢ƒå˜é‡

| å˜é‡å | è¯´æ˜ | é»˜è®¤å€¼ |
|--------|------|--------|
| `OPENAI_API_KEY` | OpenAI APIå¯†é’¥ | å¿…éœ€ |
| `OPENAI_MODEL` | ä½¿ç”¨çš„æ¨¡å‹ | `gpt-4o-mini` |

### ç³»ç»Ÿé™åˆ¶

- æœ€å¤§æ–‡ä»¶å¤§å°: 50MB
- æ”¯æŒæ ¼å¼: PDF
- æ‰¹é‡å¤„ç†: æœ€å¤š10ä¸ªæ–‡ä»¶
- æŸ¥è¯¢é•¿åº¦: æœ€å¤š1000å­—ç¬¦

## ğŸ”§ æ•…éšœæ’é™¤

### å¸¸è§é—®é¢˜

1. **ImportError: No module named 'xxx'**
   ```bash
   pip install -r requirements.txt
   ```

2. **OpenAI APIé”™è¯¯**
   - æ£€æŸ¥APIå¯†é’¥æ˜¯å¦æ­£ç¡®è®¾ç½®
   - ç¡®è®¤è´¦æˆ·æœ‰è¶³å¤Ÿä½™é¢

3. **æ–‡ä»¶ä¸Šä¼ å¤±è´¥**
   - æ£€æŸ¥æ–‡ä»¶å¤§å°æ˜¯å¦è¶…è¿‡50MB
   - ç¡®è®¤æ–‡ä»¶æ ¼å¼ä¸ºPDF

4. **ç´¢å¼•æ„å»ºå¤±è´¥**
   - æ£€æŸ¥å­˜å‚¨ç›®å½•æƒé™
   - ç¡®è®¤ChromaDBæ­£å¸¸å·¥ä½œ

### æ—¥å¿—æŸ¥çœ‹

```bash
# æŸ¥çœ‹åº”ç”¨æ—¥å¿—
tail -f llamareport-backend.log

# æŸ¥çœ‹è¯¦ç»†é”™è¯¯
python main.py --log-level debug
```

## ğŸ“ˆ æ€§èƒ½ä¼˜åŒ–

### å»ºè®®é…ç½®

- **å†…å­˜**: æœ€å°‘4GBï¼Œæ¨è8GB+
- **å­˜å‚¨**: SSDæ¨èï¼Œè‡³å°‘10GBå¯ç”¨ç©ºé—´
- **ç½‘ç»œ**: ç¨³å®šçš„äº’è”ç½‘è¿æ¥ï¼ˆOpenAI APIï¼‰

### ä¼˜åŒ–å»ºè®®

1. ä½¿ç”¨SSDå­˜å‚¨æå‡æ–‡ä»¶å¤„ç†é€Ÿåº¦
2. å¢åŠ å†…å­˜ä»¥å¤„ç†å¤§å‹æ–‡æ¡£
3. è€ƒè™‘ä½¿ç”¨æœ¬åœ°LLMå‡å°‘APIè°ƒç”¨

## ğŸ¤ è´¡çŒ®

æ¬¢è¿æäº¤Issueå’ŒPull Requestï¼

## ğŸ“„ è®¸å¯è¯

MIT License

## ğŸ“ æ”¯æŒ

å¦‚æœ‰é—®é¢˜ï¼Œè¯·æäº¤Issueæˆ–è”ç³»å¼€å‘å›¢é˜Ÿã€‚

---

**ç®€åŒ–ç‰ˆç‰¹ç‚¹**:
- âœ… ç§»é™¤äº†Streamlitå‰ç«¯
- âœ… ä¸“æ³¨æ ¸å¿ƒåŠŸèƒ½
- âœ… ä»£ç é‡å‡å°‘70%
- âœ… ä¾èµ–å‡å°‘60%
- âœ… å¯åŠ¨é€Ÿåº¦æå‡80%
