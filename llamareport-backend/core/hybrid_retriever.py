"""
Hybrid Retriever - æ··åˆæ£€ç´¢å™¨
åŸºäºè¯­ä¹‰ç›¸ä¼¼åº¦ Ã— æŒ‡æ ‡åŠ æƒ Ã— å¹´ä»½è¿‡æ»¤çš„è´¢åŠ¡æ•°æ®æ£€ç´¢ç³»ç»Ÿ
"""

import re
import logging
from typing import List, Dict, Any, Optional, Tuple
from datetime import datetime
from llama_index.core import Document, VectorStoreIndex, StorageContext
from llama_index.vector_stores.chroma import ChromaVectorStore
from llama_index.core.retrievers import VectorIndexRetriever
import chromadb

logger = logging.getLogger(__name__)

class HybridRetrievalScorer:
    """æ··åˆæ£€ç´¢è¯„åˆ†å™¨"""
    
    def __init__(self):
        # æƒé‡é…ç½®
        self.weights = {
            'semantic_similarity': 0.6,  # è¯­ä¹‰ç›¸ä¼¼åº¦æƒé‡
            'metric_matching': 0.3,      # æŒ‡æ ‡åŒ¹é…åº¦æƒé‡
            'year_consistency': 0.1      # å¹´ä»½ä¸€è‡´æ€§æƒé‡
        }
        
        # è´¢åŠ¡æŒ‡æ ‡å…³é”®è¯åº“
        self.financial_metrics = [
            'å‡€åˆ©æ¶¦', 'ROE', 'ROA', 'è´Ÿå€ºç‡', 'èµ„äº§è´Ÿå€ºç‡', 'æµåŠ¨æ¯”ç‡',
            'è¥ä¸šæ”¶å…¥', 'è¥ä¸šåˆ©æ¶¦', 'æ¯›åˆ©ç‡', 'å‡€åˆ©ç‡', 'èµ„äº§å‘¨è½¬ç‡',
            'ç°é‡‘æµ', 'è‚¡ä¸œæƒç›Š', 'æ€»èµ„äº§', 'æ€»è´Ÿå€º', 'æ¯è‚¡æ”¶ç›Š',
            'å‡€èµ„äº§', 'æµåŠ¨èµ„äº§', 'éæµåŠ¨èµ„äº§', 'æµåŠ¨è´Ÿå€º', 'éæµåŠ¨è´Ÿå€º',
            'è¥ä¸šæˆæœ¬', 'é”€å”®è´¹ç”¨', 'ç®¡ç†è´¹ç”¨', 'è´¢åŠ¡è´¹ç”¨', 'ç ”å‘è´¹ç”¨'
        ]
        
        # è´¢åŠ¡æŒ‡æ ‡åŒä¹‰è¯
        self.financial_synonyms = {
            'å‡€åˆ©æ¶¦': ['å‡€åˆ©æ¶¦', 'ç›ˆä½™', 'æ”¶ç›Š', 'Profit', 'Earnings', 'å‡€åˆ©'],
            'ROE': ['ROE', 'å‡€èµ„äº§æ”¶ç›Šç‡', 'æƒç›Šå›æŠ¥ç‡', 'Return on Equity'],
            'è¥ä¸šæ”¶å…¥': ['è¥ä¸šæ”¶å…¥', 'è¥æ”¶', 'æ”¶å…¥', 'Revenue', 'Sales'],
            'èµ„äº§': ['èµ„äº§', 'Assets', 'æ€»èµ„äº§', 'å‡€èµ„äº§'],
            'è´Ÿå€º': ['è´Ÿå€º', 'Liabilities', 'æ€»è´Ÿå€º', 'å€ºåŠ¡']
        }
    
    def calculate_comprehensive_score(self, 
                                    query: str, 
                                    document: Document, 
                                    semantic_score: float) -> Dict[str, Any]:
        """è®¡ç®—ç»¼åˆè¯„åˆ†"""
        
        # 1. è¯­ä¹‰ç›¸ä¼¼åº¦ (sim_score)
        sim_score = semantic_score
        
        # 2. æŒ‡æ ‡åŒ¹é…åº¦ (metric_score)
        metric_score = self._calculate_metric_score(query, document)
        
        # 3. å¹´ä»½ä¸€è‡´æ€§ (year_score)
        year_score = self._calculate_year_score(query, document)
        
        # 4. ç»¼åˆè¯„åˆ†
        comprehensive_score = (
            sim_score * self.weights['semantic_similarity'] +
            metric_score * self.weights['metric_matching'] +
            year_score * self.weights['year_consistency']
        )
        
        return {
            'comprehensive_score': comprehensive_score,
            'sim_score': sim_score,
            'metric_score': metric_score,
            'year_score': year_score,
            'weights': self.weights
        }
    
    def _calculate_metric_score(self, query: str, document: Document) -> float:
        """è®¡ç®—æŒ‡æ ‡åŒ¹é…åº¦"""
        query_lower = query.lower()
        doc_text = document.text.lower()
        
        # æ£€æŸ¥æŸ¥è¯¢ä¸­çš„è´¢åŠ¡æŒ‡æ ‡
        query_metrics = [metric for metric in self.financial_metrics 
                        if metric in query_lower]
        
        if not query_metrics:
            return 0.5  # ä¸­æ€§åˆ†æ•°
        
        # æ£€æŸ¥æ–‡æ¡£ä¸­æ˜¯å¦åŒ…å«è¿™äº›æŒ‡æ ‡
        matched_metrics = [metric for metric in query_metrics 
                          if metric in doc_text]
        
        # è®¡ç®—åŒ¹é…åº¦
        base_score = len(matched_metrics) / len(query_metrics)
        
        # é¢å¤–åŠ åˆ†ï¼šå¦‚æœæ–‡æ¡£æ˜¯è¡¨æ ¼ç±»å‹ä¸”åŒ…å«è´¢åŠ¡æŒ‡æ ‡
        if document.metadata.get('doc_type') == 'table' and matched_metrics:
            base_score += 0.2
        
        return min(base_score, 1.0)
    
    def _calculate_year_score(self, query: str, document: Document) -> float:
        """è®¡ç®—å¹´ä»½ä¸€è‡´æ€§"""
        # ä»æŸ¥è¯¢ä¸­æå–å¹´ä»½
        query_years = self._extract_years_from_text(query)
        
        if not query_years:
            return 0.0
        
        # ä»æ–‡æ¡£å…ƒæ•°æ®ä¸­è·å–å¹´ä»½
        doc_year = document.metadata.get('year')
        if not doc_year:
            return 0.0
        
        # æ£€æŸ¥å¹´ä»½åŒ¹é…
        if str(doc_year) in query_years:
            return 1.0
        else:
            return 0.0
    
    def _extract_years_from_text(self, text: str) -> List[str]:
        """ä»æ–‡æœ¬ä¸­æå–å¹´ä»½ä¿¡æ¯"""
        patterns = [
            r'(\d{4})-(\d{4})å¹´',  # 2020-2022å¹´
            r'(\d{4})å¹´',          # 2023å¹´
            r'(\d{4})åˆ°(\d{4})',   # 2020åˆ°2022
            r'(\d{4})è‡³(\d{4})',   # 2020è‡³2022
            r'è¿‘(\d)å¹´',           # è¿‘ä¸‰å¹´
        ]
        
        years = []
        for pattern in patterns:
            matches = re.findall(pattern, text)
            for match in matches:
                if isinstance(match, tuple):
                    if len(match) == 2:  # å¹´ä»½èŒƒå›´
                        start_year, end_year = match
                        years.extend(range(int(start_year), int(end_year) + 1))
                    elif len(match) == 1:  # è¿‘Nå¹´
                        n_years = int(match[0])
                        current_year = datetime.now().year
                        years.extend(range(current_year - n_years + 1, current_year + 1))
                else:
                    years.append(int(match))
        
        return [str(year) for year in sorted(set(years))]

class QueryExpansion:
    """æŸ¥è¯¢æ‰©å±•å™¨"""
    
    def __init__(self):
        self.financial_synonyms = {
            'å‡€åˆ©æ¶¦': ['å‡€åˆ©æ¶¦', 'ç›ˆä½™', 'æ”¶ç›Š', 'Profit', 'Earnings', 'å‡€åˆ©'],
            'ROE': ['ROE', 'å‡€èµ„äº§æ”¶ç›Šç‡', 'æƒç›Šå›æŠ¥ç‡', 'Return on Equity'],
            'è¥ä¸šæ”¶å…¥': ['è¥ä¸šæ”¶å…¥', 'è¥æ”¶', 'æ”¶å…¥', 'Revenue', 'Sales'],
            'èµ„äº§': ['èµ„äº§', 'Assets', 'æ€»èµ„äº§', 'å‡€èµ„äº§'],
            'è´Ÿå€º': ['è´Ÿå€º', 'Liabilities', 'æ€»è´Ÿå€º', 'å€ºåŠ¡'],
            'ç°é‡‘æµ': ['ç°é‡‘æµ', 'ç°é‡‘æµé‡', 'Cash Flow', 'ç»è¥ç°é‡‘æµ'],
            'æ¯›åˆ©ç‡': ['æ¯›åˆ©ç‡', 'Gross Margin', 'æ¯›åˆ©æ¶¦ç‡'],
            'å‡€åˆ©ç‡': ['å‡€åˆ©ç‡', 'Net Margin', 'å‡€åˆ©æ¶¦ç‡']
        }
    
    def expand_query(self, query: str) -> str:
        """æ‰©å±•æŸ¥è¯¢è¯"""
        expanded_terms = []
        
        for term, synonyms in self.financial_synonyms.items():
            if term in query:
                expanded_terms.extend(synonyms)
        
        if expanded_terms:
            return f"{query} {' '.join(expanded_terms)}"
        
        return query

class HybridRetriever:
    """æ··åˆæ£€ç´¢å™¨"""
    
    def __init__(self, storage_dir: str = "./storage"):
        self.storage_dir = storage_dir
        self.scorer = HybridRetrievalScorer()
        self.query_expander = QueryExpansion()
        
        # åŒé€šé“ç´¢å¼•
        self.text_index = None
        self.table_index = None
        
        # ChromaDBå®¢æˆ·ç«¯
        self.chroma_client = None
        self.text_collection = None
        self.table_collection = None
        
        # åˆå§‹åŒ–ChromaDB
        self._setup_chroma()
    
    def _setup_chroma(self):
        """è®¾ç½®ChromaDB"""
        try:
            chroma_persist_dir = f"{self.storage_dir}/chroma_hybrid"
            
            self.chroma_client = chromadb.PersistentClient(path=chroma_persist_dir)
            
            # åˆ›å»ºä¸¤ä¸ªé›†åˆ
            try:
                self.text_collection = self.chroma_client.get_collection("text_index")
            except:
                self.text_collection = self.chroma_client.create_collection("text_index")
            
            try:
                self.table_collection = self.chroma_client.get_collection("table_index")
            except:
                self.table_collection = self.chroma_client.create_collection("table_index")
            
            logger.info("âœ… Hybrid Retriever ChromaDBåˆå§‹åŒ–æˆåŠŸ")
            
        except Exception as e:
            logger.error(f"âŒ ChromaDBåˆå§‹åŒ–å¤±è´¥: {str(e)}")
    
    def build_hybrid_index(self, processed_documents: Dict, extracted_tables: Dict) -> bool:
        """æ„å»ºæ··åˆæ£€ç´¢ç´¢å¼•"""
        try:
            logger.info("ğŸš€ å¼€å§‹æ„å»ºHybrid Retrieverç´¢å¼•")
            
            # 1. æ„å»ºæ–‡æœ¬ç´¢å¼•
            text_documents = []
            for doc_name, doc_data in processed_documents.items():
                for doc in doc_data['documents']:
                    doc.metadata.update({
                        'doc_type': 'text',
                        'channel': 'text_index',
                        'source_file': doc_name
                    })
                    text_documents.append(doc)
            
            if text_documents:
                text_vector_store = ChromaVectorStore(chroma_collection=self.text_collection)
                text_storage_context = StorageContext.from_defaults(vector_store=text_vector_store)
                self.text_index = VectorStoreIndex.from_documents(
                    text_documents,
                    storage_context=text_storage_context
                )
                logger.info(f"âœ… æ–‡æœ¬ç´¢å¼•æ„å»ºå®Œæˆ: {len(text_documents)}ä¸ªæ–‡æ¡£")
            
            # 2. æ„å»ºè¡¨æ ¼ç´¢å¼•
            table_documents = []
            for doc_name, tables in extracted_tables.items():
                for table in tables:
                    table_text = self._table_to_text(table)
                    table_doc = Document(
                        text=table_text,
                        metadata={
                            'doc_type': 'table',
                            'channel': 'table_index',
                            'indicator': table.get('summary', ''),
                            'year': self._extract_year_from_table(table),
                            'source': f"{doc_name}_page_{table['page_number']}",
                            'table_id': table['table_id'],
                            'is_financial': table.get('is_financial', False)
                        }
                    )
                    table_documents.append(table_doc)
            
            if table_documents:
                table_vector_store = ChromaVectorStore(chroma_collection=self.table_collection)
                table_storage_context = StorageContext.from_defaults(vector_store=table_vector_store)
                self.table_index = VectorStoreIndex.from_documents(
                    table_documents,
                    storage_context=table_storage_context
                )
                logger.info(f"âœ… è¡¨æ ¼ç´¢å¼•æ„å»ºå®Œæˆ: {len(table_documents)}ä¸ªæ–‡æ¡£")
            
            logger.info("âœ… Hybrid Retrieverç´¢å¼•æ„å»ºå®Œæˆ")
            return True
            
        except Exception as e:
            logger.error(f"âŒ æ„å»ºæ··åˆç´¢å¼•å¤±è´¥: {str(e)}")
            return False
    
    def retrieve(self, query: str, top_k: int = 10, 
                strategy: str = 'auto') -> List[Dict[str, Any]]:
        """æ··åˆæ£€ç´¢"""
        try:
            # 1. æŸ¥è¯¢æ‰©å±•
            expanded_query = self.query_expander.expand_query(query)
            
            # 2. ç¡®å®šæ£€ç´¢ç­–ç•¥
            if strategy == 'auto':
                strategy = self._determine_retrieval_strategy(query)
            
            # 3. æ‰§è¡Œæ£€ç´¢
            if strategy == 'text_first':
                results = self._retrieve_text_first(expanded_query, top_k)
            elif strategy == 'table_first':
                results = self._retrieve_table_first(expanded_query, top_k)
            else:  # hybrid
                results = self._retrieve_hybrid(expanded_query, top_k)
            
            # 4. ç»¼åˆè¯„åˆ†å’Œæ’åº
            scored_results = []
            for result in results:
                score_result = self.scorer.calculate_comprehensive_score(
                    query, result['document'], result['semantic_score']
                )
                
                scored_results.append({
                    'document': result['document'],
                    'semantic_score': result['semantic_score'],
                    'comprehensive_score': score_result['comprehensive_score'],
                    'sim_score': score_result['sim_score'],
                    'metric_score': score_result['metric_score'],
                    'year_score': score_result['year_score'],
                    'strategy': strategy
                })
            
            # 5. æŒ‰ç»¼åˆè¯„åˆ†æ’åº
            scored_results.sort(key=lambda x: x['comprehensive_score'], reverse=True)
            
            # 6. è¿”å›Top-Kç»“æœ
            return scored_results[:top_k]
            
        except Exception as e:
            logger.error(f"âŒ æ··åˆæ£€ç´¢å¤±è´¥: {str(e)}")
            return []
    
    def _determine_retrieval_strategy(self, query: str) -> str:
        """ç¡®å®šæ£€ç´¢ç­–ç•¥"""
        # æ•°å€¼ç±»å…³é”®è¯
        numeric_keywords = ['å¢é•¿ç‡', 'å˜åŒ–å¹…åº¦', 'åŒæ¯”', 'ç¯æ¯”', 'æ•°æ®', 'æ•°å€¼', 'é‡‘é¢', 'æ¯”ä¾‹']
        
        # è¯­ä¹‰åˆ†æç±»å…³é”®è¯  
        semantic_keywords = ['è¡¨ç°å¦‚ä½•', 'è¶‹åŠ¿è¯´æ˜', 'åˆ†æ', 'è¯„ä»·', 'æƒ…å†µ', 'æ¦‚è¿°']
        
        if any(keyword in query for keyword in numeric_keywords):
            return 'table_first'  # è¡¨æ ¼ä¼˜å…ˆ
        elif any(keyword in query for keyword in semantic_keywords):
            return 'text_first'   # æ–‡æœ¬ä¼˜å…ˆ
        else:
            return 'hybrid'       # æ··åˆæ£€ç´¢
    
    def _retrieve_text_first(self, query: str, top_k: int) -> List[Dict[str, Any]]:
        """æ–‡æœ¬ä¼˜å…ˆæ£€ç´¢"""
        results = []
        
        if self.text_index:
            retriever = VectorIndexRetriever(index=self.text_index, similarity_top_k=top_k)
            nodes = retriever.retrieve(query)
            
            for node in nodes:
                results.append({
                    'document': node,
                    'semantic_score': getattr(node, 'score', 0.0)
                })
        
        return results
    
    def _retrieve_table_first(self, query: str, top_k: int) -> List[Dict[str, Any]]:
        """è¡¨æ ¼ä¼˜å…ˆæ£€ç´¢"""
        results = []
        
        if self.table_index:
            retriever = VectorIndexRetriever(index=self.table_index, similarity_top_k=top_k)
            nodes = retriever.retrieve(query)
            
            for node in nodes:
                results.append({
                    'document': node,
                    'semantic_score': getattr(node, 'score', 0.0)
                })
        
        return results
    
    def _retrieve_hybrid(self, query: str, top_k: int) -> List[Dict[str, Any]]:
        """æ··åˆæ£€ç´¢"""
        results = []
        
        # æ–‡æœ¬æ£€ç´¢
        if self.text_index:
            text_retriever = VectorIndexRetriever(index=self.text_index, similarity_top_k=top_k//2)
            text_nodes = text_retriever.retrieve(query)
            
            for node in text_nodes:
                results.append({
                    'document': node,
                    'semantic_score': getattr(node, 'score', 0.0)
                })
        
        # è¡¨æ ¼æ£€ç´¢
        if self.table_index:
            table_retriever = VectorIndexRetriever(index=self.table_index, similarity_top_k=top_k//2)
            table_nodes = table_retriever.retrieve(query)
            
            for node in table_nodes:
                results.append({
                    'document': node,
                    'semantic_score': getattr(node, 'score', 0.0)
                })
        
        return results
    
    def _table_to_text(self, table: Dict[str, Any]) -> str:
        """å°†è¡¨æ ¼è½¬æ¢ä¸ºæ–‡æœ¬è¡¨ç¤º"""
        try:
            text_parts = []
            
            # æ·»åŠ è¡¨æ ¼åŸºæœ¬ä¿¡æ¯
            text_parts.append(f"ğŸ“Š è¡¨æ ¼æ•°æ® - {table['table_id']}")
            text_parts.append(f"ğŸ“„ æ¥æºé¡µç : ç¬¬{table['page_number']}é¡µ")
            
            if table.get('is_financial'):
                text_parts.append("ğŸ’° ç±»å‹: è´¢åŠ¡æ•°æ®è¡¨æ ¼")
            
            if table.get('summary'):
                text_parts.append(f"ğŸ“ è¡¨æ ¼æ‘˜è¦: {table['summary']}")
            
            # æ·»åŠ è¡¨æ ¼æ•°æ®
            if 'table_data' in table:
                table_data = table['table_data']
                columns = table_data['columns']
                data_rows = table_data['data']
                
                # ç”ŸæˆMarkdownè¡¨æ ¼
                text_parts.append("\n**è¡¨æ ¼å†…å®¹ï¼š**\n")
                
                # è¡¨å¤´
                header = "| " + " | ".join([str(col) for col in columns]) + " |"
                text_parts.append(header)
                
                # åˆ†éš”çº¿
                separator = "|" + "|".join(["---" for _ in columns]) + "|"
                text_parts.append(separator)
                
                # æ•°æ®è¡Œ
                max_rows = min(len(data_rows), 30)
                for row in data_rows[:max_rows]:
                    row_str = "| " + " | ".join([str(cell) if cell else "" for cell in row]) + " |"
                    text_parts.append(row_str)
                
                if len(data_rows) > max_rows:
                    text_parts.append(f"\n... (è¡¨æ ¼å…±æœ‰ {len(data_rows)} è¡Œæ•°æ®)")
            
            return "\n".join(text_parts)
            
        except Exception as e:
            logger.error(f"è¡¨æ ¼è½¬æ–‡æœ¬å¤±è´¥: {str(e)}")
            return f"è¡¨æ ¼ {table.get('table_id', 'unknown')}"
    
    def _extract_year_from_table(self, table: Dict[str, Any]) -> Optional[int]:
        """ä»è¡¨æ ¼ä¸­æå–å¹´ä»½"""
        try:
            # ä»è¡¨æ ¼æ‘˜è¦ä¸­æå–å¹´ä»½
            summary = table.get('summary', '')
            year_match = re.search(r'(\d{4})', summary)
            if year_match:
                return int(year_match.group(1))
            
            # ä»è¡¨æ ¼æ•°æ®ä¸­æå–å¹´ä»½
            if 'table_data' in table:
                table_data = table['table_data']
                for row in table_data.get('data', []):
                    for cell in row:
                        if isinstance(cell, str):
                            year_match = re.search(r'(\d{4})', cell)
                            if year_match:
                                year = int(year_match.group(1))
                                if 2000 <= year <= 2030:  # åˆç†çš„å¹´ä»½èŒƒå›´
                                    return year
            
            return None
            
        except Exception as e:
            logger.error(f"æå–å¹´ä»½å¤±è´¥: {str(e)}")
            return None
    
    def get_stats(self) -> Dict[str, Any]:
        """è·å–æ£€ç´¢å™¨ç»Ÿè®¡ä¿¡æ¯"""
        stats = {
            'text_index_ready': self.text_index is not None,
            'table_index_ready': self.table_index is not None,
            'text_collection_count': self.text_collection.count() if self.text_collection else 0,
            'table_collection_count': self.table_collection.count() if self.table_collection else 0,
            'weights': self.scorer.weights,
            'financial_metrics_count': len(self.scorer.financial_metrics)
        }
        
        return stats
