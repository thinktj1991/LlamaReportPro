"""
é‡å»ºç´¢å¼•è„šæœ¬
æ¸…ç©ºç°æœ‰ç´¢å¼•å¹¶é‡æ–°å¤„ç†æ–‡æ¡£
"""
import sys
import os
import io

# è®¾ç½®UTF-8ç¼–ç 
sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8')
sys.stderr = io.TextIOWrapper(sys.stderr.buffer, encoding='utf-8')

# æ·»åŠ çˆ¶ç›®å½•åˆ°è·¯å¾„
sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..'))

from core.rag_engine import RAGEngine
from core.document_processor import DocumentProcessor
from core.table_extractor import TableExtractor
import logging
from pathlib import Path

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

def rebuild_index(upload_dir: str = "./uploads"):
    """
    é‡å»ºç´¢å¼•
    
    Args:
        upload_dir: ä¸Šä¼ æ–‡ä»¶ç›®å½•
    """
    try:
        print("\n" + "="*100)
        print("å¼€å§‹é‡å»ºç´¢å¼•...")
        print("="*100 + "\n")
        
        # 1. åˆå§‹åŒ–ç»„ä»¶
        logger.info("1ï¸âƒ£ åˆå§‹åŒ–RAGå¼•æ“...")
        rag_engine = RAGEngine()
        
        if not rag_engine.llama_index_ready:
            logger.error("âŒ RAGå¼•æ“æœªå°±ç»ªï¼Œè¯·æ£€æŸ¥APIå¯†é’¥é…ç½®")
            return False
        
        # 2. æ¸…ç©ºç°æœ‰ç´¢å¼•
        logger.info("2ï¸âƒ£ æ¸…ç©ºç°æœ‰ç´¢å¼•...")
        if rag_engine.clear_index():
            logger.info("âœ… ç´¢å¼•å·²æ¸…ç©º")
        else:
            logger.warning("âš ï¸ æ¸…ç©ºç´¢å¼•å¤±è´¥ï¼Œç»§ç»­æ‰§è¡Œ...")
        
        # 3. æ£€æŸ¥ä¸Šä¼ ç›®å½•
        upload_path = Path(upload_dir)
        if not upload_path.exists():
            logger.error(f"âŒ ä¸Šä¼ ç›®å½•ä¸å­˜åœ¨: {upload_dir}")
            return False
        
        # 4. æŸ¥æ‰¾PDFæ–‡ä»¶
        pdf_files = list(upload_path.glob("*.pdf"))
        if not pdf_files:
            logger.warning(f"âš ï¸ åœ¨ {upload_dir} ä¸­æ²¡æœ‰æ‰¾åˆ°PDFæ–‡ä»¶")
            logger.info("è¯·å…ˆä¸Šä¼ PDFæ–‡ä»¶åˆ°è¯¥ç›®å½•")
            return False
        
        logger.info(f"3ï¸âƒ£ æ‰¾åˆ° {len(pdf_files)} ä¸ªPDFæ–‡ä»¶")
        for pdf_file in pdf_files:
            logger.info(f"   - {pdf_file.name}")
        
        # 5. å¤„ç†æ–‡æ¡£
        logger.info("4ï¸âƒ£ å¼€å§‹å¤„ç†æ–‡æ¡£...")
        doc_processor = DocumentProcessor()
        table_extractor = TableExtractor()
        
        processed_documents = {}
        
        for pdf_file in pdf_files:
            try:
                logger.info(f"\nå¤„ç†æ–‡ä»¶: {pdf_file.name}")
                
                # å¤„ç†æ–‡æ¡£
                result = doc_processor.process_file(str(pdf_file), pdf_file.name)
                processed_documents[pdf_file.name] = result
                
                logger.info(f"âœ… æ–‡æ¡£å¤„ç†å®Œæˆ: {result['page_count']} é¡µ")
                
            except Exception as e:
                logger.error(f"âŒ å¤„ç†æ–‡ä»¶å¤±è´¥ {pdf_file.name}: {str(e)}")
                continue
        
        if not processed_documents:
            logger.error("âŒ æ²¡æœ‰æˆåŠŸå¤„ç†ä»»ä½•æ–‡æ¡£")
            return False
        
        # 6. æå–è¡¨æ ¼
        logger.info("\n5ï¸âƒ£ æå–è¡¨æ ¼æ•°æ®...")
        extracted_tables = table_extractor.extract_tables(processed_documents)
        
        total_tables = sum(len(tables) for tables in extracted_tables.values())
        logger.info(f"âœ… å…±æå– {total_tables} ä¸ªè¡¨æ ¼")
        
        # 7. æ„å»ºç´¢å¼•
        logger.info("\n6ï¸âƒ£ æ„å»ºå‘é‡ç´¢å¼•...")
        if rag_engine.build_index(processed_documents, extracted_tables):
            logger.info("âœ… ç´¢å¼•æ„å»ºæˆåŠŸ")
        else:
            logger.error("âŒ ç´¢å¼•æ„å»ºå¤±è´¥")
            return False
        
        # 8. è·å–ç´¢å¼•ç»Ÿè®¡
        stats = rag_engine.get_index_stats()
        
        print("\n" + "="*100)
        print("ğŸ“Š ç´¢å¼•ç»Ÿè®¡ä¿¡æ¯")
        print("="*100)
        print(f"çŠ¶æ€: {stats.get('status', 'unknown')}")
        print(f"æ–‡æ¡£æ•°é‡: {stats.get('document_count', 0)}")
        print(f"å‘é‡æ•°é‡: {stats.get('vector_count', 0)}")
        print(f"å­˜å‚¨ç›®å½•: {stats.get('storage_dir', 'unknown')}")
        print("="*100 + "\n")
        
        # 9. æµ‹è¯•æŸ¥è¯¢
        logger.info("7ï¸âƒ£ æµ‹è¯•æŸ¥è¯¢åŠŸèƒ½...")
        test_query = "è¥ä¸šæ”¶å…¥"
        result = rag_engine.query(test_query)
        
        if not result.get('error'):
            logger.info("âœ… æŸ¥è¯¢æµ‹è¯•æˆåŠŸ")
            logger.info(f"æ‰¾åˆ° {len(result.get('sources', []))} ä¸ªç›¸å…³æ¥æº")
        else:
            logger.warning(f"âš ï¸ æŸ¥è¯¢æµ‹è¯•å¤±è´¥: {result.get('answer')}")
        
        print("\n" + "="*100)
        print("ğŸ‰ ç´¢å¼•é‡å»ºå®Œæˆï¼")
        print("="*100 + "\n")
        
        return True
        
    except Exception as e:
        logger.error(f"âŒ é‡å»ºç´¢å¼•å¤±è´¥: {str(e)}")
        import traceback
        traceback.print_exc()
        return False

if __name__ == "__main__":
    import argparse
    
    parser = argparse.ArgumentParser(description='é‡å»ºRAGç´¢å¼•')
    parser.add_argument(
        '--upload-dir',
        type=str,
        default='./uploads',
        help='ä¸Šä¼ æ–‡ä»¶ç›®å½• (é»˜è®¤: ./uploads)'
    )
    
    args = parser.parse_args()
    
    success = rebuild_index(args.upload_dir)
    
    if success:
        print("\nâœ… é‡å»ºæˆåŠŸï¼ç°åœ¨å¯ä»¥é‡æ–°å¯åŠ¨æœåŠ¡å¹¶æµ‹è¯•æŸ¥è¯¢åŠŸèƒ½ã€‚")
    else:
        print("\nâŒ é‡å»ºå¤±è´¥ï¼è¯·æ£€æŸ¥é”™è¯¯æ—¥å¿—ã€‚")
        sys.exit(1)

