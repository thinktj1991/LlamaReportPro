import streamlit as st
import os
from utils.pdf_processor import PDFProcessor
from utils.table_extractor import TableExtractor
from utils.rag_system import RAGSystem
from utils.company_comparator import CompanyComparator
from utils.state import init_state, init_processors, get_processing_stats, clear_all_data
import logging

# Configure logging
logger = logging.getLogger(__name__)

def show_upload_page():
    st.header("ðŸ“ ä¸Šä¼ ä¸Žå¤„ç†æ–‡æ¡£")
    st.markdown("ä¸Šä¼ å¹´æŠ¥å’Œå…¶ä»–è´¢åŠ¡æ–‡æ¡£è¿›è¡Œåˆ†æž")
    
    # Initialize session state safely
    init_state()
    
    # Initialize processors
    if not init_processors():
        st.error("åˆå§‹åŒ–å¤„ç†ç»„ä»¶å¤±è´¥")
        return
    
    # File upload section
    st.subheader("ðŸ“¤ ä¸Šä¼ æ–‡æ¡£")
    uploaded_files = st.file_uploader(
        "é€‰æ‹©PDFæ–‡ä»¶",
        type=['pdf'],
        accept_multiple_files=True,
        help="ä¸Šä¼ å¹´æŠ¥ã€è´¢åŠ¡æŠ¥è¡¨æˆ–å…¶ä»–PDFæ–‡æ¡£"
    )
    
    if uploaded_files:
        col1, col2 = st.columns([3, 1])
        
        with col1:
            st.info(f"å·²é€‰æ‹© {len(uploaded_files)} ä¸ªæ–‡ä»¶")
            for file in uploaded_files:
                st.write(f"â€¢ {file.name} ({file.size:,} å­—èŠ‚)")
        
        with col2:
            process_button = st.button("ðŸš€ å¤„ç†æ‰€æœ‰æ–‡ä»¶", type="primary", use_container_width=True)
        
        if process_button:
            process_uploaded_files(uploaded_files)
    
    # Display processing status
    show_processing_status()
    
    # Document management
    show_document_management()

def process_uploaded_files(uploaded_files):
    """
    Process all uploaded files with validation
    """
    total_files = len(uploaded_files)
    progress_bar = st.progress(0)
    status_text = st.empty()
    
    # Track validation and processing results
    validation_results = []
    processing_results = []
    valid_files = []
    
    try:
        # Step 1: Validate all files first
        status_text.text("ðŸ” æ­£åœ¨éªŒè¯ä¸Šä¼ çš„æ–‡ä»¶...")
        
        for uploaded_file in uploaded_files:
            is_valid, error_message = validate_pdf_file(uploaded_file)
            validation_results.append({
                'filename': uploaded_file.name,
                'is_valid': is_valid,
                'error_message': error_message,
                'file_size': uploaded_file.size
            })
            
            if is_valid:
                valid_files.append(uploaded_file)
        
        # Show validation summary
        show_validation_summary(validation_results)
        
        # If no valid files, stop processing
        if not valid_files:
            st.error("âŒ æ²¡æœ‰æœ‰æ•ˆçš„æ–‡ä»¶å¯ä»¥å¤„ç†ã€‚è¯·æ£€æŸ¥ä¸Šæ–¹çš„éªŒè¯é”™è¯¯å¹¶ä¸Šä¼ æœ‰æ•ˆçš„PDFæ–‡ä»¶ã€‚")
            return
        
        # Step 2: Process only valid files
        st.info(f"ðŸ“‹ æ­£åœ¨å¤„ç† {len(valid_files)} ä¸ªæœ‰æ•ˆæ–‡ä»¶ï¼ˆå…±ä¸Šä¼  {total_files} ä¸ªæ–‡ä»¶ï¼‰...")
        
        for i, uploaded_file in enumerate(valid_files):
            try:
                status_text.text(f"æ­£åœ¨å¤„ç† {uploaded_file.name}...")
                
                with st.spinner(f"æ­£åœ¨å¤„ç† {uploaded_file.name}..."):
                    # Process PDF
                    processed_data = st.session_state.pdf_processor.process_uploaded_file(uploaded_file)
                    
                    # Extract company information
                    company_info = st.session_state.pdf_processor.extract_company_info(processed_data['documents'])
                    processed_data['company_info'] = company_info
                    
                    # Store processed document
                    st.session_state.processed_documents[uploaded_file.name] = processed_data
                    
                    # Extract tables
                    doc_tables = st.session_state.table_extractor.extract_and_process_tables(
                        {uploaded_file.name: processed_data}
                    )
                    st.session_state.extracted_tables.update(doc_tables)
                    
                    processing_results.append({
                        'filename': uploaded_file.name,
                        'success': True,
                        'error_message': None
                    })
                    
            except Exception as file_error:
                error_msg = f"Error processing {uploaded_file.name}: {str(file_error)}"
                logger.error(error_msg)
                processing_results.append({
                    'filename': uploaded_file.name,
                    'success': False,
                    'error_message': error_msg
                })
                st.warning(f"âš ï¸ ç”±äºŽå¤„ç†é”™è¯¯è·³è¿‡äº† {uploaded_file.name}ï¼š{str(file_error)}")
            
            # Update progress
            progress = (i + 1) / len(valid_files)
            progress_bar.progress(progress)
        
        # Check if any files were successfully processed
        successful_files = [r for r in processing_results if r['success']]
        
        if not successful_files:
            st.error("âŒ æ²¡æœ‰æ–‡ä»¶èƒ½å¤ŸæˆåŠŸå¤„ç†ã€‚è¯·æ£€æŸ¥ä¸Šæ–¹çš„é”™è¯¯æ¶ˆæ¯ã€‚")
            return
        
        # Step 3: Build RAG index for successfully processed files
        status_text.text("æ­£åœ¨æž„å»ºæœç´¢ç´¢å¼•...")
        with st.spinner("æ­£åœ¨æž„å»ºæœç´¢ç´¢å¼•..."):
            success = st.session_state.rag_system.build_index(
                st.session_state.processed_documents,
                st.session_state.extracted_tables
            )
            
            if success:
                st.session_state.rag_index = st.session_state.rag_system.index
        
        # Step 4: Prepare company data for comparison
        status_text.text("æ­£åœ¨å‡†å¤‡å…¬å¸æ•°æ®...")
        with st.spinner("æ­£åœ¨å‡†å¤‡å…¬å¸æ•°æ®..."):
            company_data = st.session_state.company_comparator.prepare_company_data(
                st.session_state.processed_documents,
                st.session_state.extracted_tables
            )
            st.session_state.company_data = company_data
        
        progress_bar.progress(1.0)
        status_text.text("âœ… å¤„ç†å®Œæˆï¼")
        
        # Show final summary
        show_final_processing_summary(validation_results, processing_results)
        
        # Show processing summary
        show_processing_summary()
        
        # Auto-rerun to update the interface
        st.rerun()
        
    except Exception as e:
        logger.error(f"Error processing files: {str(e)}")
        st.error(f"å¤„ç†æ–‡ä»¶é”™è¯¯ï¼š{str(e)}")

def show_processing_status():
    """
    Display current processing status
    """
    st.subheader("ðŸ“Š å¤„ç†çŠ¶æ€")
    
    # Get processing stats safely
    stats = get_processing_stats()
    
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.metric("å·²å¤„ç†æ–‡æ¡£", stats['documents_count'])
    
    with col2:
        st.metric("å·²æå–è¡¨æ ¼", stats['tables_count'])
    
    with col3:
        rag_status = "âœ… å°±ç»ª" if stats['rag_ready'] else "âŒ æœªæž„å»º"
        st.metric("æœç´¢ç´¢å¼•", rag_status)
    
    with col4:
        st.metric("å·²è¯†åˆ«å…¬å¸", stats['companies_count'])

def show_processing_summary():
    """
    Show detailed processing summary
    """
    if not st.session_state.processed_documents:
        return
    
    st.subheader("ðŸ“‹ å¤„ç†æ‘˜è¦")
    
    for doc_name, doc_data in st.session_state.processed_documents.items():
        with st.expander(f"ðŸ“„ {doc_name}"):
            # Basic statistics
            stats = st.session_state.pdf_processor.get_processing_stats(doc_data)
            
            col1, col2, col3 = st.columns(3)
            with col1:
                st.metric("é¡µæ•°", stats['page_count'])
            with col2:
                st.metric("æ–‡æœ¬é•¿åº¦", f"{stats['text_length']:,} å­—ç¬¦")
            with col3:
                st.metric("å‘çŽ°è¡¨æ ¼", stats['tables_found'])
            
            # Company information
            company_info = doc_data.get('company_info', {})
            if company_info:
                st.write("**å…¬å¸ä¿¡æ¯ï¼š**")
                for key, value in company_info.items():
                    st.write(f"â€¢ {key.title()}: {value}")
            
            # Table details
            doc_tables = st.session_state.extracted_tables.get(doc_name, [])
            if doc_tables:
                st.write("**å·²æå–è¡¨æ ¼ï¼š**")
                for table in doc_tables:
                    financial_badge = "ðŸ’° è´¢åŠ¡" if table['is_financial'] else "ðŸ“‹ ä¸€èˆ¬"
                    importance = table['importance_score']
                    st.write(f"â€¢ {table['table_id']} - {financial_badge} - é‡è¦æ€§ï¼š{importance:.2f}")

def show_document_management():
    """
    Show document management options
    """
    if not st.session_state.processed_documents:
        return
    
    st.subheader("ðŸ—‚ï¸ æ–‡æ¡£ç®¡ç†")
    
    # Clear all data option
    col1, col2 = st.columns([3, 1])
    
    with col1:
        st.write("ç®¡ç†æ‚¨å·²å¤„ç†çš„æ–‡æ¡£å’Œæ•°æ®")
    
    with col2:
        if st.button("ðŸ—‘ï¸ æ¸…é™¤æ‰€æœ‰æ•°æ®", type="secondary", use_container_width=True):
            clear_all_data_local()

def clear_all_data_local():
    """
    Clear all processed data using the centralized function
    """
    try:
        clear_all_data()
        st.success("æ‰€æœ‰æ•°æ®å·²æˆåŠŸæ¸…é™¤ï¼")
        st.rerun()
        
    except Exception as e:
        logger.error(f"Error clearing data: {str(e)}")
        st.error(f"æ¸…é™¤æ•°æ®é”™è¯¯ï¼š{str(e)}")

# Additional helper functions
def show_validation_summary(validation_results):
    """
    Display validation results for uploaded files
    """
    if not validation_results:
        return
    
    st.subheader("ðŸ” æ–‡ä»¶éªŒè¯ç»“æžœ")
    
    valid_files = [r for r in validation_results if r['is_valid']]
    invalid_files = [r for r in validation_results if not r['is_valid']]
    
    # Summary metrics
    col1, col2, col3 = st.columns(3)
    with col1:
        st.metric("æ€»æ–‡ä»¶æ•°", len(validation_results))
    with col2:
        st.metric("âœ… æœ‰æ•ˆæ–‡ä»¶", len(valid_files), delta=None, delta_color="normal")
    with col3:
        st.metric("âŒ æ— æ•ˆæ–‡ä»¶", len(invalid_files), delta=None, delta_color="inverse")
    
    # Show valid files
    if valid_files:
        with st.expander(f"âœ… Valid Files ({len(valid_files)})", expanded=True):
            for result in valid_files:
                st.success(f"âœ… {result['filename']} ({result['file_size']:,} bytes)")
    
    # Show invalid files with error details
    if invalid_files:
        with st.expander(f"âŒ Invalid Files ({len(invalid_files)})", expanded=True):
            for result in invalid_files:
                st.error(f"âŒ {result['filename']}: {result['error_message']}")

def show_final_processing_summary(validation_results, processing_results):
    """
    Display final summary of validation and processing results
    """
    st.subheader("ðŸ“Š Processing Summary")
    
    # Calculate statistics
    total_uploaded = len(validation_results)
    valid_files = len([r for r in validation_results if r['is_valid']])
    invalid_files = total_uploaded - valid_files
    successful_processing = len([r for r in processing_results if r['success']])
    failed_processing = len([r for r in processing_results if not r['success']])
    
    # Show metrics
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.metric("ðŸ“ Uploaded", total_uploaded)
    
    with col2:
        st.metric("âœ… Valid", valid_files)
    
    with col3:
        st.metric("ðŸš€ Processed", successful_processing)
    
    with col4:
        st.metric("âŒ Failed", invalid_files + failed_processing)
    
    # Show processing errors if any
    failed_files = [r for r in processing_results if not r['success']]
    if failed_files:
        with st.expander("âš ï¸ Processing Errors", expanded=False):
            for result in failed_files:
                st.warning(f"âš ï¸ {result['filename']}: {result['error_message']}")
    
    # Show success message
    if successful_processing > 0:
        if successful_processing == total_uploaded:
            st.success(f"ðŸŽ‰ All {total_uploaded} files processed successfully!")
        else:
            st.success(f"âœ… Successfully processed {successful_processing} out of {total_uploaded} files")

def validate_pdf_file(uploaded_file) -> tuple[bool, str]:
    """
    Validate uploaded PDF file with comprehensive checks
    Returns (is_valid, error_message)
    """
    try:
        # Check file size (limit to 50MB)
        if uploaded_file.size > 50 * 1024 * 1024:
            return False, f"File {uploaded_file.name} is too large ({uploaded_file.size:,} bytes). Please upload files smaller than 50MB."
        
        # Check minimum file size (100 bytes)
        if uploaded_file.size < 100:
            return False, f"File {uploaded_file.name} appears to be empty or corrupted."
        
        # Check file extension
        if not uploaded_file.name.lower().endswith('.pdf'):
            return False, f"File {uploaded_file.name} is not a PDF file. Only PDF files are supported."
        
        # Validate filename (check for valid characters and length)
        import re
        filename = uploaded_file.name
        if len(filename) > 255:
            return False, f"Filename {filename} is too long. Please use a shorter filename."
        
        # Check for potentially problematic characters
        if re.search(r'[<>:"/\\|?*]', filename):
            return False, f"Filename {filename} contains invalid characters. Please use only letters, numbers, spaces, hyphens, and underscores."
        
        # Validate PDF header by reading first few bytes
        uploaded_file.seek(0)  # Reset file pointer
        header = uploaded_file.read(8)
        uploaded_file.seek(0)  # Reset again for future use
        
        if not header.startswith(b'%PDF-'):
            return False, f"File {uploaded_file.name} does not appear to be a valid PDF (invalid header)."
        
        # Try to open with pdfplumber for basic PDF structure validation
        import pdfplumber
        try:
            with pdfplumber.open(uploaded_file) as pdf:
                # Check if PDF has any pages
                if len(pdf.pages) == 0:
                    return False, f"File {uploaded_file.name} contains no pages."
                
                # Try to access first page to ensure PDF is readable
                first_page = pdf.pages[0]
                _ = first_page.extract_text()  # This will raise an exception if PDF is corrupted
                
        except Exception as pdf_error:
            return False, f"File {uploaded_file.name} appears to be corrupted or unreadable: {str(pdf_error)}"
        finally:
            uploaded_file.seek(0)  # Reset file pointer
        
        return True, ""
        
    except Exception as e:
        logger.error(f"Error validating file {uploaded_file.name}: {str(e)}")
        return False, f"Unexpected error validating {uploaded_file.name}: {str(e)}"

# Main execution for Streamlit multipage
if __name__ == "__main__":
    show_upload_page()
