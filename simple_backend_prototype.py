#!/usr/bin/env python3
"""
ç®€åŒ–çš„åç«¯APIåŸå‹
æ¼”ç¤ºå¦‚ä½•å°†æ ¸å¿ƒåŠŸèƒ½è½¬æ¢ä¸ºAPIæ¥å£
"""

from fastapi import FastAPI, UploadFile, File, HTTPException
from fastapi.responses import JSONResponse
from pydantic import BaseModel
from typing import List, Dict, Any, Optional
import os
import tempfile
import shutil
from pathlib import Path
from dotenv import load_dotenv

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

# éªŒè¯å¿…è¦çš„ç¯å¢ƒå˜é‡
if not os.getenv("OPENAI_API_KEY"):
    raise ValueError("OPENAI_API_KEY is required")

app = FastAPI(
    title="LlamaReport Backend API",
    description="ç®€åŒ–çš„å¹´æŠ¥åˆ†æåç«¯API",
    version="1.0.0"
)

# å…¨å±€å˜é‡å­˜å‚¨å¤„ç†çŠ¶æ€
processed_documents: Dict[str, Any] = {}
rag_engine = None

class QueryRequest(BaseModel):
    question: str
    document_id: Optional[str] = None

class QueryResponse(BaseModel):
    answer: str
    sources: List[Dict[str, Any]]
    document_id: Optional[str] = None

@app.on_event("startup")
async def startup_event():
    """åº”ç”¨å¯åŠ¨æ—¶åˆå§‹åŒ–"""
    global rag_engine
    
    try:
        # åˆå§‹åŒ–RAGå¼•æ“
        from llama_index.core import VectorStoreIndex, StorageContext
        from llama_index.vector_stores.chroma import ChromaVectorStore
        import chromadb
        
        # åˆ›å»ºæŒä¹…åŒ–çš„ChromaDBå®¢æˆ·ç«¯
        storage_dir = Path("./storage_simple")
        storage_dir.mkdir(exist_ok=True)
        
        chroma_client = chromadb.PersistentClient(path=str(storage_dir))
        
        # å°è¯•è·å–ç°æœ‰é›†åˆï¼Œå¦‚æœä¸å­˜åœ¨åˆ™åˆ›å»º
        try:
            chroma_collection = chroma_client.get_collection("documents")
        except:
            chroma_collection = chroma_client.create_collection("documents")
        
        vector_store = ChromaVectorStore(chroma_collection=chroma_collection)
        storage_context = StorageContext.from_defaults(vector_store=vector_store)
        
        # å°è¯•åŠ è½½ç°æœ‰ç´¢å¼•ï¼Œå¦‚æœä¸å­˜åœ¨åˆ™åˆ›å»ºç©ºç´¢å¼•
        try:
            rag_engine = VectorStoreIndex.from_vector_store(
                vector_store, storage_context=storage_context
            )
        except:
            rag_engine = VectorStoreIndex([], storage_context=storage_context)
        
        print("âœ… RAGå¼•æ“åˆå§‹åŒ–æˆåŠŸ")
        
    except Exception as e:
        print(f"âŒ RAGå¼•æ“åˆå§‹åŒ–å¤±è´¥: {e}")
        rag_engine = None

@app.get("/")
async def root():
    """æ ¹è·¯å¾„ï¼Œè¿”å›APIä¿¡æ¯"""
    return {
        "message": "LlamaReport Backend API",
        "version": "1.0.0",
        "status": "running",
        "endpoints": [
            "/upload - ä¸Šä¼ PDFæ–‡ä»¶",
            "/process/{document_id} - å¤„ç†æ–‡æ¡£",
            "/query - RAGé—®ç­”",
            "/documents - è·å–æ–‡æ¡£åˆ—è¡¨",
            "/status - ç³»ç»ŸçŠ¶æ€"
        ]
    }

@app.get("/status")
async def get_status():
    """è·å–ç³»ç»ŸçŠ¶æ€"""
    return {
        "rag_engine_ready": rag_engine is not None,
        "documents_count": len(processed_documents),
        "openai_configured": bool(os.getenv("OPENAI_API_KEY")),
        "storage_path": "./storage_simple"
    }

@app.post("/upload")
async def upload_file(file: UploadFile = File(...)):
    """ä¸Šä¼ PDFæ–‡ä»¶"""
    if not file.filename.lower().endswith('.pdf'):
        raise HTTPException(status_code=400, detail="åªæ”¯æŒPDFæ–‡ä»¶")
    
    try:
        # ä¿å­˜ä¸Šä¼ çš„æ–‡ä»¶
        upload_dir = Path("./uploads")
        upload_dir.mkdir(exist_ok=True)
        
        file_path = upload_dir / file.filename
        with open(file_path, "wb") as buffer:
            shutil.copyfileobj(file.file, buffer)
        
        # ç”Ÿæˆæ–‡æ¡£ID
        document_id = file.filename.replace('.pdf', '').replace(' ', '_')
        
        # å­˜å‚¨æ–‡æ¡£ä¿¡æ¯
        processed_documents[document_id] = {
            "filename": file.filename,
            "file_path": str(file_path),
            "status": "uploaded",
            "processed": False
        }
        
        return {
            "document_id": document_id,
            "filename": file.filename,
            "status": "uploaded",
            "message": "æ–‡ä»¶ä¸Šä¼ æˆåŠŸï¼Œè¯·è°ƒç”¨ /process æ¥å£å¤„ç†æ–‡æ¡£"
        }
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"æ–‡ä»¶ä¸Šä¼ å¤±è´¥: {str(e)}")

@app.post("/process/{document_id}")
async def process_document(document_id: str):
    """å¤„ç†æ–‡æ¡£ï¼Œæå–å†…å®¹å¹¶å»ºç«‹ç´¢å¼•"""
    if document_id not in processed_documents:
        raise HTTPException(status_code=404, detail="æ–‡æ¡£ä¸å­˜åœ¨")
    
    doc_info = processed_documents[document_id]
    if doc_info["processed"]:
        return {"message": "æ–‡æ¡£å·²ç»å¤„ç†è¿‡", "document_id": document_id}
    
    try:
        from llama_index.readers.file import PDFReader
        from llama_index.core import Document
        
        # è¯»å–PDFæ–‡ä»¶
        pdf_reader = PDFReader()
        documents = pdf_reader.load_data(Path(doc_info["file_path"]))
        
        # æ·»åŠ å…ƒæ•°æ®
        for doc in documents:
            doc.metadata["document_id"] = document_id
            doc.metadata["filename"] = doc_info["filename"]
        
        # æ·»åŠ åˆ°RAGç´¢å¼•
        if rag_engine is not None:
            rag_engine.insert_nodes([doc.as_node() for doc in documents])
        
        # æ›´æ–°å¤„ç†çŠ¶æ€
        processed_documents[document_id].update({
            "status": "processed",
            "processed": True,
            "page_count": len(documents),
            "total_text_length": sum(len(doc.text) for doc in documents)
        })
        
        return {
            "document_id": document_id,
            "status": "processed",
            "page_count": len(documents),
            "total_text_length": sum(len(doc.text) for doc in documents),
            "message": "æ–‡æ¡£å¤„ç†å®Œæˆï¼Œå¯ä»¥è¿›è¡Œé—®ç­”æŸ¥è¯¢"
        }
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"æ–‡æ¡£å¤„ç†å¤±è´¥: {str(e)}")

@app.post("/query", response_model=QueryResponse)
async def query_documents(request: QueryRequest):
    """RAGé—®ç­”æŸ¥è¯¢"""
    if rag_engine is None:
        raise HTTPException(status_code=500, detail="RAGå¼•æ“æœªåˆå§‹åŒ–")
    
    try:
        # åˆ›å»ºæŸ¥è¯¢å¼•æ“
        query_engine = rag_engine.as_query_engine()
        
        # æ‰§è¡ŒæŸ¥è¯¢
        response = query_engine.query(request.question)
        
        # æå–æ¥æºä¿¡æ¯
        sources = []
        if hasattr(response, 'source_nodes'):
            for node in response.source_nodes:
                source_info = {
                    "document_id": node.metadata.get("document_id", "unknown"),
                    "filename": node.metadata.get("filename", "unknown"),
                    "text_snippet": node.text[:200] + "..." if len(node.text) > 200 else node.text,
                    "score": getattr(node, 'score', 0.0)
                }
                sources.append(source_info)
        
        return QueryResponse(
            answer=str(response),
            sources=sources,
            document_id=request.document_id
        )
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"æŸ¥è¯¢å¤±è´¥: {str(e)}")

@app.get("/documents")
async def get_documents():
    """è·å–å·²å¤„ç†çš„æ–‡æ¡£åˆ—è¡¨"""
    return {
        "documents": processed_documents,
        "total_count": len(processed_documents)
    }

@app.delete("/documents/{document_id}")
async def delete_document(document_id: str):
    """åˆ é™¤æ–‡æ¡£"""
    if document_id not in processed_documents:
        raise HTTPException(status_code=404, detail="æ–‡æ¡£ä¸å­˜åœ¨")
    
    try:
        doc_info = processed_documents[document_id]
        
        # åˆ é™¤æ–‡ä»¶
        if os.path.exists(doc_info["file_path"]):
            os.remove(doc_info["file_path"])
        
        # ä»å†…å­˜ä¸­åˆ é™¤
        del processed_documents[document_id]
        
        return {"message": f"æ–‡æ¡£ {document_id} åˆ é™¤æˆåŠŸ"}
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"åˆ é™¤å¤±è´¥: {str(e)}")

if __name__ == "__main__":
    import uvicorn
    
    print("ğŸš€ å¯åŠ¨ç®€åŒ–çš„åç«¯APIæœåŠ¡...")
    print("ğŸ“– APIæ–‡æ¡£: http://localhost:8000/docs")
    print("ğŸ” äº¤äº’å¼API: http://localhost:8000/redoc")
    
    uvicorn.run(
        "simple_backend_prototype:app",
        host="0.0.0.0",
        port=8000,
        reload=True,
        log_level="info"
    )
